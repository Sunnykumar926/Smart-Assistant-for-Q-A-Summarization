# ğŸ¤– Smart Assistant for Research Summarization

A **Streamlit-based GenAI application** that reads and understands content from user-uploaded `.pdf` and `.txt` files. It provides **contextual question answering**, **logic-based question generation**, and **source-grounded feedback**, powered by **Google Gemini 1.5** via LangChain.

ğŸ“ Upload research papers, legal documents, or technical reports â€” let the assistant read, reason, and quiz you!

---

## ğŸ¯ Project Objective

This project was developed as part of a GenAI recruitment task to build an **AI-powered assistant** that:

- **Understands** complex documents
- **Answers** free-form user questions with supporting evidence
- **Generates** logic-based questions to test comprehension
- **Evaluates** answers with contextual feedback
- **Justifies** all outputs with references from the document

---

## ğŸš€ Features

- ğŸ“„ **Document Upload**: Accepts `.pdf` and `.txt` files for analysis.
- âœï¸ **Auto Summary**: Instantly generates a <150 word summary per document.
- ğŸ§  **Ask Anything**: Ask detailed questions; the assistant answers with quotes from the document.
- ğŸ¯ **Challenge Me Mode**:
  - Auto-generates logic-based questions from document content
  - Lets users attempt answers
  - Evaluates and justifies with reference-backed feedback
- ğŸ” **Document Grounding**: Every response is traceable to its source â€” no hallucination.

---

## ğŸ§  How It Works

### ğŸ“ Document Parsing
- Uses **PyPDF2** and UTF-8 decoding to extract structured content.
- Groups content by document name and page number for traceability.

### ğŸ” Vector Store
- Documents are chunked using `RecursiveCharacterTextSplitter`.
- Stored locally using **FAISS** and **Google GenerativeAI Embeddings**.

### ğŸ’¬ Q&A + Feedback Pipeline
- Uses **LangChain** with `ChatGoogleGenerativeAI` (Gemini 1.5 Flash).
- Custom prompts ensure grounded, accurate, and referenced responses.
- User answers are evaluated with a structured rubric and source citations.

---

## ğŸ—ï¸ Tech Stack

- **Streamlit** â€“ Interactive web UI
- **LangChain** â€“ Chain-based Q&A and prompt engineering
- **Google Gemini 1.5** â€“ LLM backend (via `langchain-google-genai`)
- **FAISS** â€“ Local vector storage and semantic retrieval
- **PyPDF2** â€“ PDF parsing
- **dotenv** â€“ Environment variable management

---

## ğŸ“¦ Installation

### ğŸ§° Prerequisites

- Python 3.8+
- Google Gemini API Key (add to `.env` as `GOOGLE_API_KEY`)

### ğŸ”§ Setup
1. Clone repository:
```bash
git clone https://github.com/yourusername/smart-assistant-genai.git
cd smart-assistant-genai
```

2. Create virtual environment:
```bash
python -m venv my_env
source my_env/bin/activate  # Linux/MacOS
my_env\Scripts\activate    # Windows
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```
4. Create `.env` file with your API key:
```bash
GOOGLE_API_KEY=your_api_key_here
```
5. Run your file
```bash
streamlit run app.py
```















